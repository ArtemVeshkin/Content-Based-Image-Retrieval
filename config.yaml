mode: eval
feature_extractors:
  stat:
    type: stat
    args: [ ]
    n_features: 12
  conv:
    type: conv
    args: [ './CBIR/models/conv_v1.h5' ]
    n_features: 64
  VAE:
    type: VAE
    nn_config: local
    args: ${feature_extractors.VAE.VAE_args.${feature_extractors.VAE.nn_config}}
    n_features: 32
    VAE_args:
      local: [
        # model_path
#           '/home/artem/dev/Content-Based-Image-Retrieval/CBIR/models/VAE_checkpoint',
#            '/home/artem/dev/Content-Based-Image-Retrieval/Checkpoints/VAE/AE_checkpoint_[16,32,64,128,256,512]_256_192_2',
            '/home/artem/dev/Content-Based-Image-Retrieval/Checkpoints/VAE_checkpoint',
        # model_params
        [
            192, # input_size
            3, #in_channels
            32, #latent_dims
            [ 16, 32, 64, 128, 256, 512 ], # hidden_dims
            2 # n_conv_layers
        ]
      ]
features_serialization:
  path: /home/artem/dev/Content-Based-Image-Retrieval/CBIR_serialized
scalenet:
  checkpoint_path: /home/artem/dev/Content-Based-Image-Retrieval/CBIR/models/ScaleNet_best_[16,32,64,128,256]_[128,32]
  input_size: 224
  grayscale_input: False
  conv_hidden_dims: [ 16,32,64,128,256 ]
  conv_out_size: 2
  fc_hidden_dims: [ 128,32 ]
eval:
  data_path: /home/artem/data/PATH-DT-MSU-WSI/patches-wsi-224-val-z2-balanced/
  classes: [
    { name: AT, n_queries: 10 },
#    { name: BG, n_queries: 10 },
    { name: LP, n_queries: 10 },
    { name: MM, n_queries: 10 },
    { name: TUM, n_queries: 10 }
  ]
#  data_path: /home/artem/data/NCT-CRC-HE-100K/
#  classes: [
#    { name: ADI, n_queries: 10 },
#    { name: BACK, n_queries: 10 },
#    { name: DEB, n_queries: 10 },
#    { name: LYM, n_queries: 10 },
#    { name: MUC, n_queries: 10 },
#    { name: MUS, n_queries: 10 },
#    { name: NORM, n_queries: 10 },
#    { name: STR, n_queries: 10 },
#    { name: TUM, n_queries: 10 },
#  ]
  feature_extractor_type: stat
  feature_extractor: ${feature_extractors.${eval.feature_extractor_type}}
  binarization: True
  filter: 'c2' # 'c2'/'no filter'
  distance: 'c2_d_near' # 'mse'/'c2_d_near'/'c2_d_ave'
  features_serialization: ${features_serialization}
  tile_size: 192
  save_results: False
  top_n: 10
  LSH_k_bits: 16
  scalenet: ${scalenet}
CBIR_test:
  feature_extractor_type: stat
  feature_extractor: ${feature_extractors.${CBIR_test.feature_extractor_type}}
  features_serialization: ${features_serialization}
  scalenet: ${scalenet}
  scale_detection:
    test_wsi: /home/artem/data/PATH-DT-MSU-WSI/WSS2/01.svs
    scales: [5, 10, 15, 20, 25, 30, 35, 40]
    n_samples: 20
  tile_size: 192
  save_results: True
  top_n: 10
  binarization: True
  filter: 'c2' # 'c2'/'no filter'
  distance: 'c2_d_near' # 'mse'/'c2_d_near'/'c2_d_ave'
  LSH_k_bits: 16
  query: /home/artem/data/PATH-DT-MSU-WSI/patches-wsi-224-val-z2/TUM/000010.jpg
data_generation:
  level: 1 # Levels are numbered from 0 (the highest resolution) to level_count - 1
  image_dir: /home/artem/data/PATH-DT-MSU-WSI/WSS2/
  output_dir: /home/artem/dev/Content-Based-Image-Retrieval/VAE_data/train/
  skip_images: [ '6.svs',
                 '8.svs' ]
  n_images: 100000
  tile_size: [ 224, 224 ]
fit_VAE:
  use_AE: True
  use_MNIST: False
  skip_background: True
  load_checkpoint: False
  load_path: /home/artem/dev/Content-Based-Image-Retrieval/Checkpoints/VAE_checkpoint
  save_every_steps: 100
  save_path: /home/artem/dev/Content-Based-Image-Retrieval/Checkpoints/VAE_checkpoint
  image_dir: /home/artem/dev/Content-Based-Image-Retrieval/VAE_data/train
#  image_dir: [
#    '/home/artem/data/PATH-DT-MSU-WSI/patches-wsi-224-val-z2/AT/',
#    '/home/artem/data/PATH-DT-MSU-WSI/patches-wsi-224-val-z2/LP/',
#    '/home/artem/data/PATH-DT-MSU-WSI/patches-wsi-224-val-z2/MM/',
#    '/home/artem/data/PATH-DT-MSU-WSI/patches-wsi-224-val-z2/TUM/',
#  ]
#  image_dir: [
#    '/home/artem/data/NCT-CRC-HE-100K/ADI/',
#    '/home/artem/data/NCT-CRC-HE-100K/BACK/',
#    '/home/artem/data/NCT-CRC-HE-100K/DEB/',
#    '/home/artem/data/NCT-CRC-HE-100K/LYM/',
#    '/home/artem/data/NCT-CRC-HE-100K/MUC/',
#    '/home/artem/data/NCT-CRC-HE-100K/MUS/',
#    '/home/artem/data/NCT-CRC-HE-100K/NORM/',
#    '/home/artem/data/NCT-CRC-HE-100K/STR/',
#    '/home/artem/data/NCT-CRC-HE-100K/TUM/',
#  ]
  summarywriter_logdir: tensorboard_logs
  input_size: 192
  in_channels: 3
  lattent_dims: 32
  hidden_dims: [ 16, 32, 64, 128, 256, 512 ]
  n_conv_layers: 2
  recons_loss: mse
  KLD_weight: 0.0000001
  var_weight: 0
  batch_size: 8
  lr: 0.00005
  weight_decay: 0
  max_steps: 1000000
  sample_after_training: True
  n_samples: 4
fit_scalenet:
  train_path: /home/artem/dev/Content-Based-Image-Retrieval/WSI_scale_data/train
  eval_path: /home/artem/dev/Content-Based-Image-Retrieval/WSI_scale_data/eval
  summarywriter_logdir: tensorboard_logs
  checkpoint_path: /home/artem/dev/Content-Based-Image-Retrieval/Checkpoints/ScaleNet/checkpoint
  load_from_checkpoint: True
  save_every_steps: 1000
  log_every_steps: 10
  input_size: 224
  grayscale_input: False
  conv_hidden_dims: [16,32,64,128,256]
  conv_out_size: 2
  fc_hidden_dims: [128,32]
  eval_only: False
  batch_size: 128
  n_batches: 1
  training_steps: 200000
  eval_every_steps: 500
  eval_num_steps: 50
  lr: 1e-4
  weight_decay: 0
extractor_visualization:
  visualization_type: knn_distance
  feature_extractor_type: VAE
  feature_extractor: ${feature_extractors.${extractor_visualization.feature_extractor_type}}
  image_dirs: [
      { path: /home/artem/dev/CBIR/data/eval/patches-wsi-224-val-z2/AT/, name: AT },
#      { path: /home/artem/dev/CBIR/data/eval/patches-wsi-224-val-z2/BG/, name: BG },
      { path: /home/artem/dev/CBIR/data/eval/patches-wsi-224-val-z2/LP/, name: LP },
      { path: /home/artem/dev/CBIR/data/eval/patches-wsi-224-val-z2/MM/, name: MM },
      { path: /home/artem/dev/CBIR/data/eval/patches-wsi-224-val-z2/TUM/, name: TUM }
    ]
  clusters:
    n_plots: [ 2, 4 ] # (w, h)
    image_dirs: ${extractor_visualization.image_dirs}
    n_tiles: 150
  class_distances:
    image_dirs: ${extractor_visualization.image_dirs}
    n_queries: 10
    n_candidates: 100
    metric: mse
  knn_distance:
    image_dirs: ${extractor_visualization.image_dirs}
    k: 10
    n_candidates: 10
    n_queries: 100
    metric: mse
  transformation:
    image_dirs: ${extractor_visualization.image_dirs}
    scale: 0.5
    source: AT
    target: LP
    steps: 3
    gif_path: transform.gif
    gif_len: 7000
    pre_frames: 20
    post_frames: 20

